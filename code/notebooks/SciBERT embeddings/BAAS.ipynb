{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BAAS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e97c821000a346ad9dba4c1143fb97f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_308a467398054116a354ff424eaa62f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b8f481691a2419e93af6a9393377352",
              "IPY_MODEL_54dec68f01324b12a06af5b776b8724c"
            ]
          }
        },
        "308a467398054116a354ff424eaa62f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b8f481691a2419e93af6a9393377352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a79eceb78d844d7499a54bb3312f97a7",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_406e9a693a2846baa447d00966c0c3c5"
          }
        },
        "54dec68f01324b12a06af5b776b8724c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41d4be768bb848b488c686b000df154d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1000 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2a831cacaf643b8b6e0261f794147d7"
          }
        },
        "a79eceb78d844d7499a54bb3312f97a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "406e9a693a2846baa447d00966c0c3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41d4be768bb848b488c686b000df154d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2a831cacaf643b8b6e0261f794147d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgYCVDANtE0e"
      },
      "source": [
        "# Starting the Bert server encoding for embedding retreival"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ahjnorFYDfn",
        "outputId": "e4367d51-3a4e-484e-ae4b-5f80d1ce08d4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noC3F8irslSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895ea2e2-608e-44f8-f409-14f3d90db84e"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbimWNduAoyu"
      },
      "source": [
        "# Here we don't have the model checkpoint anymore but you can generate it with the SciBERT notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwQGJGjeRsC1",
        "outputId": "4b07f4c3-58ab-4463-927a-24713f2a96e6"
      },
      "source": [
        "# !gdown https://drive.google.com/uc?id=1jYkmAhdEdGwZs2kgcwWMVz6x0htnTIJu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jYkmAhdEdGwZs2kgcwWMVz6x0htnTIJu\n",
            "To: /content/model.ckpt\n",
            "1.27GB [00:06, 189MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ciZMH-YMF1"
      },
      "source": [
        "\"\"\"Convert Huggingface Pytorch checkpoint to Tensorflow checkpoint.\"\"\"\r\n",
        "\r\n",
        "import os\r\n",
        "import argparse\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from transformers import AutoModel\r\n",
        "\r\n",
        "\r\n",
        "def convert_pytorch_checkpoint_to_tf(model, ckpt_dir, model_name):\r\n",
        "    tensors_to_transpose = (\r\n",
        "        \"dense.weight\",\r\n",
        "        \"attention.self.query\",\r\n",
        "        \"attention.self.key\",\r\n",
        "        \"attention.self.value\"\r\n",
        "    )\r\n",
        "\r\n",
        "    var_map = (\r\n",
        "        ('layer.', 'layer_'),\r\n",
        "        ('word_embeddings.weight', 'word_embeddings'),\r\n",
        "        ('position_embeddings.weight', 'position_embeddings'),\r\n",
        "        ('token_type_embeddings.weight', 'token_type_embeddings'),\r\n",
        "        ('.', '/'),\r\n",
        "        ('LayerNorm/weight', 'LayerNorm/gamma'),\r\n",
        "        ('LayerNorm/bias', 'LayerNorm/beta'),\r\n",
        "        ('weight', 'kernel')\r\n",
        "    )\r\n",
        "\r\n",
        "    if not os.path.isdir(ckpt_dir):\r\n",
        "        os.makedirs(ckpt_dir)\r\n",
        "\r\n",
        "    state_dict = model.state_dict()\r\n",
        "\r\n",
        "    def to_tf_var_name(name:str):\r\n",
        "        for patt, repl in iter(var_map):\r\n",
        "            name = name.replace(patt, repl)\r\n",
        "        return 'bert/{}'.format(name)\r\n",
        "\r\n",
        "    def create_tf_var(tensor:np.ndarray, name:str, session:tf.Session):\r\n",
        "        tf_dtype = tf.dtypes.as_dtype(tensor.dtype)\r\n",
        "        tf_var = tf.get_variable(dtype=tf_dtype, shape=tensor.shape, name=name, initializer=tf.zeros_initializer())\r\n",
        "        session.run(tf.variables_initializer([tf_var]))\r\n",
        "        session.run(tf_var)\r\n",
        "        return tf_var\r\n",
        "\r\n",
        "    tf.reset_default_graph()\r\n",
        "    with tf.Session() as session:\r\n",
        "        for var_name in state_dict:\r\n",
        "            tf_name = to_tf_var_name(var_name)\r\n",
        "            torch_tensor = state_dict[var_name].numpy()\r\n",
        "            if any([x in var_name for x in tensors_to_transpose]):\r\n",
        "                torch_tensor = torch_tensor.T\r\n",
        "            tf_var = create_tf_var(tensor=torch_tensor, name=tf_name, session=session)\r\n",
        "            tf.keras.backend.set_value(tf_var, torch_tensor)\r\n",
        "            tf_weight = session.run(tf_var)\r\n",
        "            print(\"Successfully created {}: {}\".format(tf_name, np.allclose(tf_weight, torch_tensor)))\r\n",
        "\r\n",
        "        saver = tf.train.Saver(tf.trainable_variables())\r\n",
        "        saver.save(session, os.path.join(ckpt_dir, model_name.replace(\"-\", \"_\") + \".ckpt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4nTu2KcdDpO",
        "outputId": "ba65cf10-4f33-4355-e2ce-cfeee64e81f9"
      },
      "source": [
        "pytorch_model_path = 'model.ckpt'\r\n",
        "model_name = 'allenai/scibert_scivocab_uncased'\r\n",
        "tf_cache_dir = 'tf_model/'\r\n",
        "\r\n",
        "model = AutoModel.from_pretrained(\r\n",
        "    pretrained_model_name_or_path=model_name,\r\n",
        "    state_dict=torch.load(pytorch_model_path),\r\n",
        ")\r\n",
        "print(\"after model\")\r\n",
        "    \r\n",
        "convert_pytorch_checkpoint_to_tf(\r\n",
        "    model=model,\r\n",
        "    ckpt_dir=tf_cache_dir,\r\n",
        "    model_name=model_name\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['iter', 'model_state_dict', 'optimizer_state_dict']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "after model\n",
            "Successfully created bert/embeddings/position_ids: True\n",
            "Successfully created bert/embeddings/word_embeddings: True\n",
            "Successfully created bert/embeddings/position_embeddings: True\n",
            "Successfully created bert/embeddings/token_type_embeddings: True\n",
            "Successfully created bert/embeddings/LayerNorm/gamma: True\n",
            "Successfully created bert/embeddings/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_0/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_0/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_0/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_0/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_0/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_0/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_0/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_0/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_0/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_0/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_0/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_0/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_0/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_0/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_0/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_0/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_1/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_1/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_1/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_1/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_1/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_1/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_1/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_1/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_1/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_1/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_1/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_1/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_1/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_1/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_1/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_1/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_2/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_2/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_2/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_2/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_2/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_2/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_2/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_2/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_2/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_2/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_2/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_2/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_2/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_2/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_2/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_2/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_3/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_3/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_3/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_3/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_3/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_3/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_3/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_3/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_3/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_3/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_3/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_3/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_3/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_3/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_3/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_3/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_4/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_4/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_4/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_4/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_4/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_4/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_4/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_4/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_4/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_4/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_4/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_4/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_4/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_4/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_4/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_4/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_5/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_5/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_5/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_5/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_5/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_5/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_5/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_5/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_5/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_5/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_5/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_5/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_5/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_5/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_5/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_5/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_6/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_6/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_6/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_6/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_6/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_6/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_6/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_6/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_6/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_6/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_6/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_6/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_6/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_6/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_6/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_6/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_7/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_7/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_7/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_7/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_7/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_7/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_7/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_7/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_7/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_7/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_7/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_7/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_7/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_7/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_7/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_7/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_8/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_8/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_8/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_8/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_8/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_8/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_8/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_8/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_8/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_8/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_8/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_8/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_8/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_8/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_8/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_8/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_9/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_9/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_9/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_9/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_9/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_9/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_9/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_9/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_9/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_9/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_9/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_9/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_9/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_9/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_9/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_9/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_10/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_10/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_10/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_10/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_10/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_10/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_10/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_10/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_10/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_10/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_10/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_10/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_10/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_10/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_10/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_10/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_11/attention/self/query/kernel: True\n",
            "Successfully created bert/encoder/layer_11/attention/self/query/bias: True\n",
            "Successfully created bert/encoder/layer_11/attention/self/key/kernel: True\n",
            "Successfully created bert/encoder/layer_11/attention/self/key/bias: True\n",
            "Successfully created bert/encoder/layer_11/attention/self/value/kernel: True\n",
            "Successfully created bert/encoder/layer_11/attention/self/value/bias: True\n",
            "Successfully created bert/encoder/layer_11/attention/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_11/attention/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_11/attention/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_11/attention/output/LayerNorm/beta: True\n",
            "Successfully created bert/encoder/layer_11/intermediate/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_11/intermediate/dense/bias: True\n",
            "Successfully created bert/encoder/layer_11/output/dense/kernel: True\n",
            "Successfully created bert/encoder/layer_11/output/dense/bias: True\n",
            "Successfully created bert/encoder/layer_11/output/LayerNorm/gamma: True\n",
            "Successfully created bert/encoder/layer_11/output/LayerNorm/beta: True\n",
            "Successfully created bert/pooler/dense/kernel: True\n",
            "Successfully created bert/pooler/dense/bias: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBC0NuteswUB",
        "outputId": "75c58d8f-de9e-4c8d-998c-839d3b94ae61"
      },
      "source": [
        "!wget https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/tensorflow_models/scibert_scivocab_uncased.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-09 17:02:37--  https://s3-us-west-2.amazonaws.com/ai2-s2-research/scibert/tensorflow_models/scibert_scivocab_uncased.tar.gz\n",
            "Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 52.218.178.24\n",
            "Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|52.218.178.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1216161420 (1.1G) [application/x-tar]\n",
            "Saving to: ‘scibert_scivocab_uncased.tar.gz’\n",
            "\n",
            "scibert_scivocab_un 100%[===================>]   1.13G  37.9MB/s    in 31s     \n",
            "\n",
            "2021-02-09 17:03:09 (36.9 MB/s) - ‘scibert_scivocab_uncased.tar.gz’ saved [1216161420/1216161420]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j2Q4OS0FZUa"
      },
      "source": [
        "!tar -xf scibert_scivocab_uncased.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a-bXz84svD0",
        "outputId": "94d03c5f-6b60-445c-f8a6-1c00d66d6371"
      },
      "source": [
        "!pip install bert-serving-client\r\n",
        "!pip install -U bert-serving-server[http]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-client\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.19.5)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (22.0.2)\n",
            "Installing collected packages: bert-serving-client\n",
            "Successfully installed bert-serving-client-1.10.0\n",
            "Collecting bert-serving-server[http]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (22.0.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.15.0)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Collecting flask-compress; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/7a/9c4641f975fb9daaf945dc39da6a52fd5693ab3bbc2d53780eab3b5106f4/Flask_Compress-1.8.0-py3-none-any.whl\n",
            "Collecting flask-cors; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Collecting flask-json; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/2d/4c21d98b11f3a206fabbdd965b53a2ca3ee9fab7646c93cf36c060e8f1a4/Flask_JSON-0.3.4-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: flask; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: bert-serving-client; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.10.0)\n",
            "Collecting brotli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/d3/7c98f05b7b9103e2f3a112ba42f269c798155b3e5404fb80bb8f823aaebe/Brotli-1.0.9-cp36-cp36m-manylinux1_x86_64.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask; extra == \"http\"->bert-serving-server[http]) (1.1.1)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=98ecf0e086ea2e76dd90a9e3adbf98133d44ac269183e8acbea59e76b4d9548e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, brotli, flask-compress, flask-cors, flask-json, bert-serving-server\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 brotli-1.0.9 flask-compress-1.8.0 flask-cors-3.0.10 flask-json-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-GuoFNXsxiC"
      },
      "source": [
        "# starting the client with 256 as maximum sequence length (trimmed right), first embedding and two last hidden state layers\r\n",
        "!nohup bert-serving-start -max_seq_len 256 -pooling_layer -1 -num_worker=4 -gpu_memory_fraction 0.8 -model_dir=./scibert_scivocab_uncased > out.file 2>&1 &\r\n",
        "# !bert-serving-start -max_seq_len 512 -pooling_layer -1 -num_worker=2 -tuned_model_dir=./tf_model/allenai/ -ckpt_name=scibert_scivocab_uncased.ckpt -gpu_memory_fraction 0.8 -model_dir=./scibert_scivocab_uncased > out.file 2>&1 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt6BD44z6nws",
        "outputId": "c9be2a35-318c-4ab6-f1fe-a34bc1a94d20"
      },
      "source": [
        "!cat out.file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I:\u001b[35mVENTILATOR\u001b[0m:[__i:__i: 67]:freeze, optimize and export graph, could take a while...\n",
            "usage: /usr/local/bin/bert-serving-start -max_seq_len 256 -pooling_layer -1 -num_worker=4 -gpu_memory_fraction 0.8 -model_dir=./scibert_scivocab_uncased\n",
            "                 ARG   VALUE\n",
            "__________________________________________________\n",
            "           ckpt_name = bert_model.ckpt\n",
            "         config_name = bert_config.json\n",
            "                cors = *\n",
            "                 cpu = False\n",
            "          device_map = []\n",
            "       do_lower_case = True\n",
            "  fixed_embed_length = False\n",
            "                fp16 = False\n",
            " gpu_memory_fraction = 0.8\n",
            "       graph_tmp_dir = None\n",
            "    http_max_connect = 10\n",
            "           http_port = None\n",
            "        mask_cls_sep = False\n",
            "      max_batch_size = 256\n",
            "         max_seq_len = 256\n",
            "           model_dir = ./scibert_scivocab_uncased\n",
            "no_position_embeddings = False\n",
            "    no_special_token = False\n",
            "          num_worker = 4\n",
            "       pooling_layer = [-1]\n",
            "    pooling_strategy = REDUCE_MEAN\n",
            "                port = 5555\n",
            "            port_out = 5556\n",
            "       prefetch_size = 10\n",
            " priority_batch_size = 16\n",
            "show_tokens_to_client = False\n",
            "     tuned_model_dir = None\n",
            "             verbose = False\n",
            "                 xla = False\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_serving/server/helper.py:186: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_serving/server/helper.py:186: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
            "\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: ./scibert_scivocab_uncased/bert_config.json\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: ./scibert_scivocab_uncased/bert_model.ckpt\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEr6XFWLs0Iw",
        "outputId": "0846ae2c-f1eb-4465-f7ef-dfbab55cb4b8"
      },
      "source": [
        "from bert_serving.client import BertClient\r\n",
        "bert_client = BertClient(check_length=False)\r\n",
        "\r\n",
        "list_text = ['you '* 240 + 'only', 'Nan']\r\n",
        "embedded_text = bert_client.encode(list_text)\r\n",
        "embedding_dim = len(embedded_text[1])\r\n",
        "print(f\"Encoding dimension: {embedding_dim}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoding dimension: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcOSodnWtUHN"
      },
      "source": [
        "# Reading our abstracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30I5kq_cxnlF",
        "outputId": "75c01898-5b2b-49bc-978f-99930a8e658d"
      },
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1w8cCfCd9A_Ph6jIVTs34pVZMOhKTiX0m\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w8cCfCd9A_Ph6jIVTs34pVZMOhKTiX0m\n",
            "To: /content/abstract_train_full.csv\n",
            "103MB [00:01, 56.7MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNvqfWDzpJDg",
        "outputId": "5660a22f-75db-4aeb-efc9-bf70f5e598a0"
      },
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1RqwwBkarpAEZ0Zs1SVxndjI5mhtwZre5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RqwwBkarpAEZ0Zs1SVxndjI5mhtwZre5\n",
            "To: /content/abstract_test_full.csv\n",
            "919MB [00:09, 98.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGBDAtv2pfxm",
        "outputId": "4c3b5202-5f40-43cb-db68-bde8ce56e365"
      },
      "source": [
        "import numpy as np\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "df_train = pd.read_csv(\"abstract_train_full.csv\", index_col=0)\r\n",
        "df_test = pd.read_csv(\"abstract_test_full.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "MRyH5SZ3xpKu",
        "outputId": "44644dfb-4188-4e1b-9ec2-b0680f448b30"
      },
      "source": [
        "df_author_abstract = pd.concat([df_train, df_test])\r\n",
        "del df_author_abstract[\"h_index\"]\r\n",
        "df_author_abstract = df_author_abstract[df_author_abstract[\"abstract\"] != \"\\n\"]\r\n",
        "df_author_abstract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authorID</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7248981</td>\n",
              "      <td>fuelled bring internet things concept real int...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7248981</td>\n",
              "      <td>recent advances mobile devices network technol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7248981</td>\n",
              "      <td>several research groups working designing new ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7248981</td>\n",
              "      <td>next generation internet provide ubiquitous co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7248981</td>\n",
              "      <td>recent huge trend towards running network inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081145</th>\n",
              "      <td>2908506980</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081146</th>\n",
              "      <td>2908506980</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081147</th>\n",
              "      <td>2908506980</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081148</th>\n",
              "      <td>2908506980</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081149</th>\n",
              "      <td>2908506980</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2312329 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           authorID                                           abstract\n",
              "0           7248981  fuelled bring internet things concept real int...\n",
              "1           7248981  recent advances mobile devices network technol...\n",
              "2           7248981  several research groups working designing new ...\n",
              "3           7248981  next generation internet provide ubiquitous co...\n",
              "4           7248981  recent huge trend towards running network inte...\n",
              "...             ...                                                ...\n",
              "2081145  2908506980                                                NaN\n",
              "2081146  2908506980                                                NaN\n",
              "2081147  2908506980                                                NaN\n",
              "2081148  2908506980                                                NaN\n",
              "2081149  2908506980                                                NaN\n",
              "\n",
              "[2312329 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBZQmw9ELyLJ"
      },
      "source": [
        "def process_batch(group_df, author_to_embeddings, author_count_abstracts):\r\n",
        "    abstract_batch = group_df.iloc[:, 1].values\r\n",
        "    stringified_batches = [str(x) for x in abstract_batch]\r\n",
        "    nan_indices = set(np.where(np.array(stringified_batches) == 'nan')[0])\r\n",
        "    embeddings = bert_client.encode(stringified_batches)\r\n",
        "    for i, author_id in enumerate(group_df[\"authorID\"]):\r\n",
        "        if i not in nan_indices:\r\n",
        "            author_to_embeddings[author_id] += embeddings[i]\r\n",
        "            author_count_abstracts[author_id] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJJexefnuNJZ",
        "outputId": "041983e8-69c2-4ff0-9864-fb7a224d56c2"
      },
      "source": [
        "n_splits = 1000\r\n",
        "print(f\"Total abstracts in each of the {n_splits} groups: {len(df_author_abstract)*10 // n_splits}\")\r\n",
        "# maps author to list of its embeddings: 1245334 -> list of shape (10, 768)\r\n",
        "author_to_embeddings = {\r\n",
        "    author_id: np.zeros(embedding_dim) for author_id in df_author_abstract[\"authorID\"]\r\n",
        "}\r\n",
        "author_count_abstracts = {\r\n",
        "    author_id: 0 for author_id in df_author_abstract[\"authorID\"]\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total abstracts in each of the 1000 groups: 23123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e97c821000a346ad9dba4c1143fb97f7",
            "308a467398054116a354ff424eaa62f8",
            "2b8f481691a2419e93af6a9393377352",
            "54dec68f01324b12a06af5b776b8724c",
            "a79eceb78d844d7499a54bb3312f97a7",
            "406e9a693a2846baa447d00966c0c3c5",
            "41d4be768bb848b488c686b000df154d",
            "c2a831cacaf643b8b6e0261f794147d7"
          ]
        },
        "id": "B_qE8y1cJMW5",
        "outputId": "d514d715-ebe4-42e0-f125-860b92ee5493"
      },
      "source": [
        "for group_df in tqdm(np.array_split(df_author_abstract, n_splits), total=n_splits):\r\n",
        "    process_batch(group_df, author_to_embeddings, author_count_abstracts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e97c821000a346ad9dba4c1143fb97f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWdS8cDvJjsO"
      },
      "source": [
        "# get the mean for each author\r\n",
        "for author_id, embedding_sum in tqdm(author_to_embeddings.items()):\r\n",
        "    abstract_count = author_count_abstracts[author_id]\r\n",
        "    if abstract_count:\r\n",
        "        author_to_embeddings[author_id] = embedding_sum / abstract_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOHgUfAIGM65"
      },
      "source": [
        "np.save('author_to_embeddings_ours.npy', author_to_embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQvUT-5OTk2D"
      },
      "source": [
        "author_retreived = np.load('author_to_embeddings_ours.npy').item()\r\n",
        "# dict {authodID: average of his abstracts embeddings (768,)}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}