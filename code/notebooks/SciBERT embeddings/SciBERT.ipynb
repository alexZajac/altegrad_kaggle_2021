{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "P-PieBERT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ed5506fe4c048e1a28ec9f21189833a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd50286a4115406096185e426e9e274d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6da9a9f7ecb8417dbd23d5a745ee4af6",
              "IPY_MODEL_717b6324718e452a99d7cc7c6e7713f5"
            ]
          }
        },
        "cd50286a4115406096185e426e9e274d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6da9a9f7ecb8417dbd23d5a745ee4af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7d5e4126e9984d1aacf5cf7fb949d74e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_964d7a3842e7462d8122bd2ca43976c9"
          }
        },
        "717b6324718e452a99d7cc7c6e7713f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87e85888ea4f4007aea037a86c222460",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:00&lt;00:00, 826B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b84d2f55f214bcebf29ae4824b6bf35"
          }
        },
        "7d5e4126e9984d1aacf5cf7fb949d74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "964d7a3842e7462d8122bd2ca43976c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87e85888ea4f4007aea037a86c222460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b84d2f55f214bcebf29ae4824b6bf35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "841377a6ac1d43ab96b29ea76b515ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_615e5eafbaf045cfb5a36f07684ca90e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f1f6ad48abf24f53895729a7bbdb334b",
              "IPY_MODEL_495ac62342a34ba5a4f140f58f6136ea"
            ]
          }
        },
        "615e5eafbaf045cfb5a36f07684ca90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1f6ad48abf24f53895729a7bbdb334b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11d81d74189e4bc0aecb5c106f7928bd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 227845,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227845,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bde365373e44d59b09010859f86b325"
          }
        },
        "495ac62342a34ba5a4f140f58f6136ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ba4cd84ea7b42179324a53a69b5bd22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 228k/228k [00:01&lt;00:00, 201kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2858b7ef8c534b05a7ffcc082e5ea1c9"
          }
        },
        "11d81d74189e4bc0aecb5c106f7928bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bde365373e44d59b09010859f86b325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ba4cd84ea7b42179324a53a69b5bd22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2858b7ef8c534b05a7ffcc082e5ea1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92331e9d9c5840e2b6643b15f6d9b564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b47b2e88b224bb29ba0f7be31397f25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbf2df5a258249b4ab57f23998c77183",
              "IPY_MODEL_521b06f70f0645499678c7694a2c0b70"
            ]
          }
        },
        "5b47b2e88b224bb29ba0f7be31397f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbf2df5a258249b4ab57f23998c77183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5cac9952fe034a15acea562c770ec437",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442221694,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442221694,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96a2e8b65f9a4817abf23e7d59492e3f"
          }
        },
        "521b06f70f0645499678c7694a2c0b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d021d511b4ed44a0ac4c3724f0c55d92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442M/442M [00:06&lt;00:00, 65.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72964b40cc5144658812b39996aaf5a3"
          }
        },
        "5cac9952fe034a15acea562c770ec437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96a2e8b65f9a4817abf23e7d59492e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d021d511b4ed44a0ac4c3724f0c55d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72964b40cc5144658812b39996aaf5a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "923b9c399b9c458e845241f06ff5e975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_090319fa1f0643d7ab82ef942e04670b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fea8e8a68d7a42458a3fdc9a078a951b",
              "IPY_MODEL_50ecbed9cc45423d969f751bbb451901"
            ]
          }
        },
        "090319fa1f0643d7ab82ef942e04670b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fea8e8a68d7a42458a3fdc9a078a951b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da35d50d1e7d4be5a7ef98509f714d76",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd3f10da71d646eaa83be835b0209d37"
          }
        },
        "50ecbed9cc45423d969f751bbb451901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f1a2d269a1e14d4b92cc36eaee3fd46b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [00:15&lt;00:00,  3.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c14f1fdc70124eb5b9899ac6e8f9e3ec"
          }
        },
        "da35d50d1e7d4be5a7ef98509f714d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd3f10da71d646eaa83be835b0209d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1a2d269a1e14d4b92cc36eaee3fd46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c14f1fdc70124eb5b9899ac6e8f9e3ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37db717d5a2746cb8bd37c489f480dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98d05a28136e417b802f9fb0c4cad85d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_439383a044f74b4db150d1906754687d",
              "IPY_MODEL_421ce278121d48deae7e2bbb9db37cf2"
            ]
          }
        },
        "98d05a28136e417b802f9fb0c4cad85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "439383a044f74b4db150d1906754687d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba46dfb62c8a4f3fa97bf69ad50fdb59",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0273b1c31eae4b6184af0ecc63d89463"
          }
        },
        "421ce278121d48deae7e2bbb9db37cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02e8397fc8534f409d61b840d9d50f29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [00:15&lt;00:00,  3.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cfa0728763a401a940ed2e8d17356ce"
          }
        },
        "ba46dfb62c8a4f3fa97bf69ad50fdb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0273b1c31eae4b6184af0ecc63d89463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02e8397fc8534f409d61b840d9d50f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cfa0728763a401a940ed2e8d17356ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgPSIom_DYEf"
      },
      "source": [
        "# Finetuning BERT ðŸš€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK1x2s1pDip2",
        "outputId": "1b487252-50e1-40a6-b3d3-fd7fc56fdc90"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/89/f07e7a884072ad37b1b6b1578637ab36152e0251d74abb950d967a59904e/transformers-4.3.1-py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=defd8be01d3bbfb2fbc6cbb3964749b788144fc6f24134e01c8397528b4abf06\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFJxASnZXYJ5"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "import torch\r\n",
        "import gc\r\n",
        "\r\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rEnBppDDcsq",
        "outputId": "1c34058b-ae37-44f9-e3a8-354ed0743717"
      },
      "source": [
        "# If there's a GPU available...\r\n",
        "if torch.cuda.is_available():    \r\n",
        "\r\n",
        "    # Tell PyTorch to use the GPU.    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "# If not...\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVWGuGx5THUX",
        "outputId": "1f71012e-0e18-40b1-f48b-f1c8453e5c5d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Feb  9 14:07:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    11W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfKkhVaP8H-X"
      },
      "source": [
        "import logging\r\n",
        "logging.basicConfig(\r\n",
        "    filename=\"log_bert.log\",\r\n",
        "    filemode='a',\r\n",
        "    format='%(asctime)s %(levelname)s %(message)s',\r\n",
        "    datefmt='%H:%M:%S',\r\n",
        "    level=logging.DEBUG\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvpNvXT-dsUQ"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJL4INdRo3WH",
        "outputId": "38dc93ca-c0cf-47ac-fabc-a6c024119f6e"
      },
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1RqwwBkarpAEZ0Zs1SVxndjI5mhtwZre5\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RqwwBkarpAEZ0Zs1SVxndjI5mhtwZre5\n",
            "To: /content/abstract_test_full.csv\n",
            "919MB [00:09, 94.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNvqfWDzpJDg",
        "outputId": "61c83390-3bad-44a3-9a4d-9e6eac9cdedb"
      },
      "source": [
        "!gdown \"https://drive.google.com/uc?id=1w8cCfCd9A_Ph6jIVTs34pVZMOhKTiX0m\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w8cCfCd9A_Ph6jIVTs34pVZMOhKTiX0m\n",
            "To: /content/abstract_train_full.csv\n",
            "103MB [00:00, 126MB/s]  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGBDAtv2pfxm",
        "outputId": "ab67da8d-49d6-454e-950a-b9a39f8cc42e"
      },
      "source": [
        "df_train = pd.read_csv(\"abstract_train_full.csv\", index_col=0)\r\n",
        "df_test = pd.read_csv(\"abstract_test_full.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSD2CHnELQ1x"
      },
      "source": [
        "df_train.fillna(\"\", inplace=True)\r\n",
        "df_test[\"abstract\"].fillna(\"\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "1zemOKQd17xw",
        "outputId": "4189cfb4-21fe-4572-d4b4-1e394d99f541"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authorID</th>\n",
              "      <th>abstract</th>\n",
              "      <th>h_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7248981</td>\n",
              "      <td>fuelled bring internet things concept real int...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7248981</td>\n",
              "      <td>recent advances mobile devices network technol...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7248981</td>\n",
              "      <td>several research groups working designing new ...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7248981</td>\n",
              "      <td>next generation internet provide ubiquitous co...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7248981</td>\n",
              "      <td>recent huge trend towards running network inte...</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231235</th>\n",
              "      <td>2908220509</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231236</th>\n",
              "      <td>2908220509</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231237</th>\n",
              "      <td>2908220509</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231238</th>\n",
              "      <td>2908220509</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231239</th>\n",
              "      <td>2908220509</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>231240 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          authorID                                           abstract  h_index\n",
              "0          7248981  fuelled bring internet things concept real int...     11.0\n",
              "1          7248981  recent advances mobile devices network technol...     11.0\n",
              "2          7248981  several research groups working designing new ...     11.0\n",
              "3          7248981  next generation internet provide ubiquitous co...     11.0\n",
              "4          7248981  recent huge trend towards running network inte...     11.0\n",
              "...            ...                                                ...      ...\n",
              "231235  2908220509                                                         1.0\n",
              "231236  2908220509                                                         1.0\n",
              "231237  2908220509                                                         1.0\n",
              "231238  2908220509                                                         1.0\n",
              "231239  2908220509                                                         1.0\n",
              "\n",
              "[231240 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "2OIBJzZY2kX5",
        "outputId": "ba2ad6c4-d882-4319-aca5-01c65fc7a7d9"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authorID</th>\n",
              "      <th>abstract</th>\n",
              "      <th>h_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1036332</td>\n",
              "      <td>underground utility conveyance may precisely l...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1036332</td>\n",
              "      <td>invention relates method system wireless netwo...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1036332</td>\n",
              "      <td>present invention system method searching larg...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1036332</td>\n",
              "      <td>method apparatus calculating engineered capaci...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1036332</td>\n",
              "      <td>method apparatus detecting abnormal calling ac...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081145</th>\n",
              "      <td>2908506980</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081146</th>\n",
              "      <td>2908506980</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081147</th>\n",
              "      <td>2908506980</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081148</th>\n",
              "      <td>2908506980</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2081149</th>\n",
              "      <td>2908506980</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2081150 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           authorID                                           abstract  h_index\n",
              "0           1036332  underground utility conveyance may precisely l...      NaN\n",
              "1           1036332  invention relates method system wireless netwo...      NaN\n",
              "2           1036332  present invention system method searching larg...      NaN\n",
              "3           1036332  method apparatus calculating engineered capaci...      NaN\n",
              "4           1036332  method apparatus detecting abnormal calling ac...      NaN\n",
              "...             ...                                                ...      ...\n",
              "2081145  2908506980                                                         NaN\n",
              "2081146  2908506980                                                         NaN\n",
              "2081147  2908506980                                                         NaN\n",
              "2081148  2908506980                                                         NaN\n",
              "2081149  2908506980                                                         NaN\n",
              "\n",
              "[2081150 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqHW0YQGZpHi"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt_gdYKfd8pk"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer, RobertaTokenizer, RobertaModel, AutoTokenizer, AutoModel\r\n",
        "\r\n",
        "MODELS = {\r\n",
        "    \"bert-base-uncased\": (BertModel, BertTokenizer, \"bert-base-uncased\"),\r\n",
        "    \"bert-large-uncased\": (BertModel, BertTokenizer, \"bert-large-uncased\"),\r\n",
        "    \"roberta-base\": (RobertaModel, RobertaTokenizer, \"roberta-base\"),\r\n",
        "    \"roberta-large\": (RobertaModel, RobertaTokenizer, \"roberta-large\"),\r\n",
        "    \"scibert_uncased\": (AutoModel, AutoTokenizer, \"allenai/scibert_scivocab_uncased\")\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfX_8MjZp_Q0"
      },
      "source": [
        "# Hyper Parameters\r\n",
        "# number of samples to take for training\r\n",
        "N = 50\r\n",
        "# Workers to load the data (4*num_gpus recommended by the pytorch team)\r\n",
        "NUM_WORKERS = 4*torch.cuda.device_count()\r\n",
        "# Maximum length fo the tokens\r\n",
        "MAX_TOKEN_LENGTH = 512\r\n",
        "# The name of the model\r\n",
        "MODEL_NAME = \"scibert_uncased\"\r\n",
        "# should we train head layer and whole network or only whole network\r\n",
        "USE_DUAL_TRAINING = True\r\n",
        "# should we use the decreasing lr strategy for the transformer\r\n",
        "USE_LR_SCHEME = False\r\n",
        "HEAD_PARAMS = {\r\n",
        "    \"epochs\": 3,\r\n",
        "    \"batch_size\": 32,\r\n",
        "    \"lr\": 1e-4\r\n",
        "}\r\n",
        "BODY_PARAMS = {\r\n",
        "    \"epochs\": 2,\r\n",
        "    \"batch_size\": 6,\r\n",
        "    \"lr\": 5e-5,\r\n",
        "    \"lr_transfo\": 3e-5,\r\n",
        "    \"lr_decay\": 0.95\r\n",
        "}\r\n",
        "# betas for AdamW\r\n",
        "ADAMW_BETAS = (0.9, 0.999)\r\n",
        "# how to divide the test df (too large to fit in memory)\r\n",
        "BATCH_SIZE_DF = len(df_test) // 1000\r\n",
        "# batches for the prediction on the test set\r\n",
        "BATCH_SIZE_TEST = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZT23ZZs8ehn"
      },
      "source": [
        "hyperparams = {\r\n",
        "    \"N\": N,\r\n",
        "    \"NUM_WORKERS\": NUM_WORKERS,\r\n",
        "    \"MAX_TOKEN_LENGTH\": MAX_TOKEN_LENGTH,\r\n",
        "    \"MODEL_NAME\": MODEL_NAME,\r\n",
        "    \"USE_DUAL_TRAINING\": USE_DUAL_TRAINING,\r\n",
        "    \"USE_LR_SCHEME\": USE_LR_SCHEME,\r\n",
        "    \"HEAD_PARAMS\": HEAD_PARAMS,\r\n",
        "    \"BODY_PARAMS\": BODY_PARAMS,\r\n",
        "    \"ADAMW_BETAS\": ADAMW_BETAS,\r\n",
        "    \"BATCH_SIZE_DF\": BATCH_SIZE_DF,\r\n",
        "    \"BATCH_SIZE_TEST\": BATCH_SIZE_TEST\r\n",
        "}\r\n",
        "logging.info(f\"Parameters for the current run: {hyperparams}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOX2B-sz_icA"
      },
      "source": [
        "## Create model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWIyq-IK_T3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "9ed5506fe4c048e1a28ec9f21189833a",
            "cd50286a4115406096185e426e9e274d",
            "6da9a9f7ecb8417dbd23d5a745ee4af6",
            "717b6324718e452a99d7cc7c6e7713f5",
            "7d5e4126e9984d1aacf5cf7fb949d74e",
            "964d7a3842e7462d8122bd2ca43976c9",
            "87e85888ea4f4007aea037a86c222460",
            "9b84d2f55f214bcebf29ae4824b6bf35",
            "841377a6ac1d43ab96b29ea76b515ee8",
            "615e5eafbaf045cfb5a36f07684ca90e",
            "f1f6ad48abf24f53895729a7bbdb334b",
            "495ac62342a34ba5a4f140f58f6136ea",
            "11d81d74189e4bc0aecb5c106f7928bd",
            "0bde365373e44d59b09010859f86b325",
            "1ba4cd84ea7b42179324a53a69b5bd22",
            "2858b7ef8c534b05a7ffcc082e5ea1c9",
            "92331e9d9c5840e2b6643b15f6d9b564",
            "5b47b2e88b224bb29ba0f7be31397f25",
            "dbf2df5a258249b4ab57f23998c77183",
            "521b06f70f0645499678c7694a2c0b70",
            "5cac9952fe034a15acea562c770ec437",
            "96a2e8b65f9a4817abf23e7d59492e3f",
            "d021d511b4ed44a0ac4c3724f0c55d92",
            "72964b40cc5144658812b39996aaf5a3"
          ]
        },
        "outputId": "27149d1d-1dcb-4063-9535-0a48e04fba2f"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = MODELS[MODEL_NAME]\r\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\r\n",
        "base_model = model_class.from_pretrained(\r\n",
        "    pretrained_weights, output_hidden_states=True\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ed5506fe4c048e1a28ec9f21189833a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "841377a6ac1d43ab96b29ea76b515ee8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=227845.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92331e9d9c5840e2b6643b15f6d9b564",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442221694.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fb75sQtFt4d"
      },
      "source": [
        "df_train = df_train.iloc[:N]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXyWxPovE_Ot"
      },
      "source": [
        "# Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O-iBCVYbTvp"
      },
      "source": [
        "def tokenize_sentence(sentence, tokenizer, **tokenizer_kwargs):\r\n",
        "    return tokenizer.encode_plus(\r\n",
        "        sentence,\r\n",
        "        **tokenizer_kwargs\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6G_JPG0mrWX"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\r\n",
        "\r\n",
        "def get_tokens_labels(df, tokenizer, progress=True, **tokenizer_kwargs):\r\n",
        "    # extract raw values\r\n",
        "    sentences = df[\"abstract\"].values\r\n",
        "    _sentences = tqdm(sentences) if progress else sentences\r\n",
        "    # tokenization\r\n",
        "    tokenized_sentences = [\r\n",
        "        tokenize_sentence(sent, tokenizer, **tokenizer_kwargs) \r\n",
        "        for sent in _sentences\r\n",
        "    ]\r\n",
        "    _tokenized_sentences = tqdm(tokenized_sentences) if progress else tokenized_sentences\r\n",
        "     # Add the encoded sentence to the list.\r\n",
        "    input_ids = [\r\n",
        "        token_dict[\"input_ids\"] for token_dict in _tokenized_sentences\r\n",
        "    ]\r\n",
        "    # Convert the lists into tensors.\r\n",
        "    input_ids = torch.cat(input_ids, dim=0)\r\n",
        "    # if we are in test mode\r\n",
        "    if df[\"h_index\"].isna().sum() > 0:\r\n",
        "        return TensorDataset(input_ids)\r\n",
        "    labels = torch.tensor(df[\"h_index\"].values, dtype=torch.float32)\r\n",
        "    # Print sentence 0, now as a list of IDs.\r\n",
        "    print('Original: ', sentences[0])\r\n",
        "    print('Token IDs:', input_ids[0])\r\n",
        "    # Combine the inputs into a TensorDataset\r\n",
        "    return TensorDataset(input_ids, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "923b9c399b9c458e845241f06ff5e975",
            "090319fa1f0643d7ab82ef942e04670b",
            "fea8e8a68d7a42458a3fdc9a078a951b",
            "50ecbed9cc45423d969f751bbb451901",
            "da35d50d1e7d4be5a7ef98509f714d76",
            "cd3f10da71d646eaa83be835b0209d37",
            "f1a2d269a1e14d4b92cc36eaee3fd46b",
            "c14f1fdc70124eb5b9899ac6e8f9e3ec",
            "37db717d5a2746cb8bd37c489f480dd7",
            "98d05a28136e417b802f9fb0c4cad85d",
            "439383a044f74b4db150d1906754687d",
            "421ce278121d48deae7e2bbb9db37cf2",
            "ba46dfb62c8a4f3fa97bf69ad50fdb59",
            "0273b1c31eae4b6184af0ecc63d89463",
            "02e8397fc8534f409d61b840d9d50f29",
            "5cfa0728763a401a940ed2e8d17356ce"
          ]
        },
        "id": "4EeKpNjuckVN",
        "outputId": "66df832f-b722-4290-8f0f-baf392aead3b"
      },
      "source": [
        "tokenizer_kwargs = {\r\n",
        "    \"add_special_tokens\": True, # Add '[CLS]' and '[SEP]'\r\n",
        "    \"max_length\": MAX_TOKEN_LENGTH,           # Pad & truncate all sentences.## a changer\r\n",
        "    \"padding\": \"max_length\",\r\n",
        "    \"return_attention_mask\": True,   # Construct attn. masks.\r\n",
        "    \"return_tensors\": \"pt\",     # Return pytorch tensors.\r\n",
        "    \"truncation\": True\r\n",
        "}\r\n",
        "\r\n",
        "logging.info(f\"Tokenizer arguments: {tokenizer_kwargs}\")\r\n",
        "dataset = get_tokens_labels(df_train, tokenizer, **tokenizer_kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "923b9c399b9c458e845241f06ff5e975",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37db717d5a2746cb8bd37c489f480dd7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Original:  fuelled bring internet things concept real internet engineering task force working standard allows vast number smart objects deployed local wireless sensor networks using huge address space data information harvesting security point open security threats local network cryptography techniques applied front line defence deterrent easily broken weak secure nature lowpan devices wireless compromised nodes could lead insider attacks without detected cryptography intrusion detection system primarily needed second line defence monitor network operations raise alarm case paper analyses potential security threats reviews current solutions countering discovers three novel security namely rank local repair resource depleting seriously affecting routing protocol lossy routing protocol used establish network new ids concept introduced countermeasure method securing routing protocol lossy network topology internal qos potential research works also presented provide baseline reference researchers copyright john wiley\n",
            "Token IDs: tensor([  102,  8086,   810,  7977,  4992,  8153,  2614,  1332,  4992,  3192,\n",
            "         2188,  3163,  3630,  1235,  2890, 10946,   649,  6786,  3200, 12160,\n",
            "         1338,  5071,  3121,  2449,   487, 11812,  2035,  1630,   453,   776,\n",
            "        16609,  3594,  1313,  1937,  3594, 15504,  1338,   934, 22999,  2190,\n",
            "         1765,  5546,   972, 20912,  9021,   704,  3717, 12265,  2973,  8446,\n",
            "         2540,   629,  3868,  3410,  5071, 15463,  2207,   968,  1269,  4970,\n",
            "        30114,  7652,  1319,  2490, 22999, 18001,  1995,   429,  5454,  2764,\n",
            "          971,   972, 20912,  2913,   934,  3878, 12517, 14961,   820,  1203,\n",
            "         2519,  1411,  3594, 15504,  7292,  1073,  2727,  4227,   140,  9819,\n",
            "        30113,   874,  3045,  3594,  5100,  3704,  1338,  5445,  3955,  7397,\n",
            "          586, 18921,  7586,  5767,  2929,  1738, 30126,  5767,  2929,   501,\n",
            "         3897,   934,   758, 17454,  2614,  3376,  4227, 15923,   551,   509,\n",
            "         2502,  5767,  2929,  1738, 30126,   934,  6344,  2924, 11314,  1411,\n",
            "          849,  4603,   469,  1632,  1584,  3263,  2470,  4538,  4586,  5760,\n",
            "         7348,   103,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5KN8CQKHoda"
      },
      "source": [
        "# Split and DataLoaders\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHKZar4ZgKh1"
      },
      "source": [
        "## Train/validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQJZscVZdDbl",
        "outputId": "d2648b7a-89f9-413f-a0f6-5c239eec7a24"
      },
      "source": [
        "# Create a 90-10 train-validation split.\r\n",
        "train_size = int(0.9 * len(dataset))\r\n",
        "val_size = len(dataset) - train_size\r\n",
        "\r\n",
        "# Divide the dataset by randomly selecting samples.\r\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\r\n",
        "\r\n",
        "print('{:>5,} training samples'.format(train_size))\r\n",
        "print('{:>5,} validation samples'.format(val_size))\r\n",
        "\r\n",
        "logging.info('{:>5,} training samples'.format(train_size))\r\n",
        "logging.info('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   45 training samples\n",
            "    5 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edM2hUf5gNPZ"
      },
      "source": [
        "## Custom Batch Sampler to speed up the training (courtesy of Theo le s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A46J25Tyf66r"
      },
      "source": [
        "from torch.utils.data.sampler import BatchSampler\r\n",
        "\r\n",
        "class LenMatchBatchSampler(BatchSampler):\r\n",
        "    \"\"\"\r\n",
        "    Custom PyTorch Sampler that generate batches of similar length.\r\n",
        "    Used alongside with trim_tensor, it helps speed up training.\r\n",
        "    \"\"\"\r\n",
        "    def __iter__(self):\r\n",
        "\r\n",
        "        buckets = [[]] * 100\r\n",
        "        yielded = 0\r\n",
        "\r\n",
        "        for idx in self.sampler:\r\n",
        "            count_zeros = torch.sum(self.sampler.data_source[idx][0] == 0)\r\n",
        "            count_zeros = int(count_zeros / 64) \r\n",
        "            if len(buckets[count_zeros]) == 0:  buckets[count_zeros] = []\r\n",
        "\r\n",
        "            buckets[count_zeros].append(idx)\r\n",
        "\r\n",
        "            if len(buckets[count_zeros]) == self.batch_size:\r\n",
        "                batch = list(buckets[count_zeros])\r\n",
        "                yield batch\r\n",
        "                yielded += 1\r\n",
        "                buckets[count_zeros] = []\r\n",
        "\r\n",
        "        batch = []\r\n",
        "        leftover = [idx for bucket in buckets for idx in bucket]\r\n",
        "\r\n",
        "        for idx in leftover:\r\n",
        "            batch.append(idx)\r\n",
        "            if len(batch) == self.batch_size:\r\n",
        "                yielded += 1\r\n",
        "                yield batch\r\n",
        "                batch = []\r\n",
        "\r\n",
        "        if len(batch) > 0 and not self.drop_last:\r\n",
        "            yielded += 1\r\n",
        "            yield batch\r\n",
        "\r\n",
        "        assert len(self) == yielded, \"produced an inccorect number of batches. expected %i, but yielded %i\" %(len(self), yielded)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def trim_tensors(tokens, min_len=10):\r\n",
        "    \"\"\"\r\n",
        "    Trim tensors so that within a batch, padding is shortened.\r\n",
        "    This speeds up training for RNNs and Transformers\r\n",
        "    \"\"\"\r\n",
        "    max_len = max(torch.max(torch.sum((tokens != 0), 1)), min_len)\r\n",
        "    return tokens[:, :max_len]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNr-MZxWQt4S"
      },
      "source": [
        "# Model classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhaZKJscmog"
      },
      "source": [
        "# Here you have to be explicit about your hs blending strategy: https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\r\n",
        "def _produce_hidden_state_combination(hidden_states):\r\n",
        "    # shape of hidden state is (num_transformers_layers, batch_size, seq_len, hidden_dim)\r\n",
        "    embedding = hidden_states[0].mean(1)\r\n",
        "    *_, h9, h10, h11, h12, _ = hidden_states\r\n",
        "    concat_last_four = torch.cat((h9, h10, h11, h12), dim=1)\r\n",
        "    mean_last_four = concat_last_four.mean(1)\r\n",
        "    hs_concat = torch.cat((embedding, mean_last_four), dim=1)\r\n",
        "    return hs_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xISlmc1Aiy-N"
      },
      "source": [
        "# Here you have to be explicit about what leayers you want for the final pooler\r\n",
        "def _produce_pooler(pooler_in_features, pooler_out_features, device=device):\r\n",
        "    return nn.Sequential(\r\n",
        "        nn.Linear(pooler_in_features, 512),\r\n",
        "        nn.Tanh(),\r\n",
        "        nn.Dropout(0.4),\r\n",
        "        nn.Linear(512, pooler_out_features),\r\n",
        "        nn.Tanh(),\r\n",
        "        nn.Dropout(0.2),\r\n",
        "    ).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnT_kg_-Szbq"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "class TransformerModel(nn.Module):\r\n",
        "    def __init__(\r\n",
        "        self, base_model, num_classes=1, pooler_in_features=None, pooler_out_features=256\r\n",
        "    ):\r\n",
        "        super().__init__()\r\n",
        "        self.base_model = base_model\r\n",
        "        # out features from the pretrained model\r\n",
        "        if not pooler_in_features:\r\n",
        "            self.pooler_in_features = self.base_model.pooler.dense.out_features\r\n",
        "        else:\r\n",
        "            self.pooler_in_features = pooler_in_features\r\n",
        "        self.h_index_pooler = _produce_pooler(\r\n",
        "            self.pooler_in_features, pooler_out_features\r\n",
        "        )\r\n",
        "        self.h_index_top_layer = nn.Linear(pooler_out_features, num_classes)\r\n",
        "\r\n",
        "    def forward(self, ids):\r\n",
        "        sequence_output, pooled_output, hidden_states = self.base_model(\r\n",
        "            ids, \r\n",
        "            attention_mask=(ids > 0), \r\n",
        "            return_dict=False\r\n",
        "        )\r\n",
        "        reduced_hidden_state = _produce_hidden_state_combination(hidden_states)\r\n",
        "        # sequence_output has the following shape: (batch_size, reduced_hidden_state_size)\r\n",
        "        pooler_output = self.h_index_pooler(reduced_hidden_state)\r\n",
        "        y = self.h_index_top_layer(pooler_output)\r\n",
        "        return torch.squeeze(y, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW0Fuks_T_uu"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqclFyQWUhKG"
      },
      "source": [
        "import time\r\n",
        "import datetime\r\n",
        "import random\r\n",
        "\r\n",
        "def format_time(elapsed):\r\n",
        "    # Round to the nearest second.\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    # Format as hh:mm:ss\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25hWgpmTO8Z7"
      },
      "source": [
        "# freeze netwrok/layers\r\n",
        "def freeze(model):\r\n",
        "    for param in model.parameters():\r\n",
        "        param.requires_grad = False\r\n",
        "\r\n",
        "def unfreeze(modem):\r\n",
        "    for param in modem.parameters():\r\n",
        "        param.requires_grad = True\r\n",
        "\r\n",
        "def unfreeze_layer(model, name):\r\n",
        "    for n, p in list(model.named_parameters()):\r\n",
        "        if name in n:\r\n",
        "            p.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDJSii0OITp5"
      },
      "source": [
        "def _get_optimization_params(\r\n",
        "    model, lr=1e-3, weight_decay=0, lr_transfo=3e-5, lr_decay=1, use_lr_scheme=USE_LR_SCHEME\r\n",
        "):\r\n",
        "    if not use_lr_scheme:\r\n",
        "        return model.parameters()\r\n",
        "    opt_params = []\r\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\r\n",
        "    nb_blocks = len(model.base_model.encoder.layer)\r\n",
        "    \r\n",
        "    for n, p in model.named_parameters():\r\n",
        "        wd = 0 if any(nd in n for nd in no_decay) else weight_decay\r\n",
        "        \r\n",
        "        if \"transformer\" in n and \"pooler\" not in n:\r\n",
        "            lr_ = lr_transfo\r\n",
        "            if \"transformer.embeddings\" in n:\r\n",
        "                lr_ = lr_transfo * lr_decay ** (nb_blocks)\r\n",
        "            else:\r\n",
        "                for i in range(nb_blocks):  # for bert base\r\n",
        "                    if f\"layer.{i}.\" in n:\r\n",
        "                        lr_ = lr_transfo * lr_decay ** (nb_blocks - 1 - i)\r\n",
        "                        break\r\n",
        "        else:\r\n",
        "            lr_ = lr\r\n",
        "\r\n",
        "        opt_params.append({\r\n",
        "         \"params\": [p], \r\n",
        "         \"weight_decay\": wd,\r\n",
        "         'lr':lr_,\r\n",
        "        })\r\n",
        "    return opt_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU8YN1j0pWMa"
      },
      "source": [
        "# Set the seed value all over the place to make this reproducible.\r\n",
        "seed_val = 42\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3z7XxJLMu7l"
      },
      "source": [
        "def fit(model, optimizer, scheduler, criterion, train_dataloader, start_time):\r\n",
        "    # Reset the total loss for this epoch.\r\n",
        "    total_train_loss = 0\r\n",
        "    # don't accumulate gradients over epochs\r\n",
        "    optimizer.zero_grad()\r\n",
        "    # train mode\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    # For each batch of training data...\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "\r\n",
        "        # Progress update every 50 batches.\r\n",
        "        if not step % 100 and step:\r\n",
        "            elapsed = format_time(time.time() - start_time)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "            logging.info('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # Unpack this training batch from our dataloader\r\n",
        "        b_input_ids = batch[0]\r\n",
        "        b_labels = batch[1].to(device)\r\n",
        "        # trim id tensor to accelerate training, since batches are ordered\r\n",
        "        b_input_ids = trim_tensors(b_input_ids).to(device)\r\n",
        "\r\n",
        "        result = model(b_input_ids)\r\n",
        "        loss = criterion(result, b_labels)\r\n",
        "        total_train_loss += loss.item()\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "        optimizer.step()\r\n",
        "        scheduler.step()\r\n",
        "        model.zero_grad()\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "    # Calculate the average loss over all of the batches.\r\n",
        "    return total_train_loss / len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGYQNtZgN-BG"
      },
      "source": [
        "def validate(model, criterion, validation_dataloader):\r\n",
        "    model.eval()\r\n",
        "    # Tracking variables \r\n",
        "    total_eval_loss = 0\r\n",
        "    nb_eval_steps = 0\r\n",
        "\r\n",
        "    # Evaluate data for one epoch\r\n",
        "    with torch.no_grad():\r\n",
        "        for batch in validation_dataloader:\r\n",
        "            b_input_ids = batch[0].to(device)\r\n",
        "            b_labels = batch[1].to(device)\r\n",
        "            \r\n",
        "            result = model(b_input_ids)\r\n",
        "            loss = criterion(result, b_labels)\r\n",
        "            total_eval_loss += loss.item()\r\n",
        "\r\n",
        "    # Calculate the average loss over all of the batches.\r\n",
        "    return total_eval_loss / len(validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCDis068I0ZC"
      },
      "source": [
        "import random\r\n",
        "import numpy as np\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "from torch.utils.data import DataLoader, RandomSampler\r\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\r\n",
        "\r\n",
        "def fit_and_eval(\r\n",
        "    model, \r\n",
        "    train_dataset, \r\n",
        "    val_dataset,\r\n",
        "    adamw_betas=ADAMW_BETAS, \r\n",
        "    epochs=2, \r\n",
        "    batch_size=16, \r\n",
        "    lr=5e-5,\r\n",
        "    weight_decay=0, \r\n",
        "    lr_transfo=3e-5, \r\n",
        "    lr_decay=1\r\n",
        "):\r\n",
        "    # training_stats = []\r\n",
        "    total_t0 = time.time()\r\n",
        "\r\n",
        "    ## Loss (mean reduction by default)\r\n",
        "    criterion = nn.L1Loss().cuda()\r\n",
        "\r\n",
        "    # Create the DataLoaders for our training and validation sets.\r\n",
        "    len_sampler = LenMatchBatchSampler(\r\n",
        "        RandomSampler(train_dataset), \r\n",
        "        batch_size=batch_size, \r\n",
        "        drop_last=True\r\n",
        "    )\r\n",
        "    train_dataloader = DataLoader(\r\n",
        "        train_dataset,  # The training samples.\r\n",
        "        batch_sampler=len_sampler, # Select batches not randomly (by size)\r\n",
        "        num_workers=NUM_WORKERS, # Trains with this batch size.\r\n",
        "        pin_memory=True\r\n",
        "    )\r\n",
        "    # For validation the order doesn't matter, so we'll just read them sequentially.\r\n",
        "    validation_dataloader = DataLoader(\r\n",
        "        val_dataset, # The validation samples.\r\n",
        "        shuffle=False, # Pull out batches sequentially.\r\n",
        "        batch_size=batch_size, # Evaluate with this batch size.\r\n",
        "        num_workers=NUM_WORKERS,\r\n",
        "        pin_memory=True\r\n",
        "    )\r\n",
        "\r\n",
        "    # Optimization params\r\n",
        "    opt_params = _get_optimization_params(model)\r\n",
        "    # logging.info(f\"Optimization parameters for ADAMW: {opt_params}\")\r\n",
        "    optimizer = AdamW(opt_params, lr=lr, betas=adamw_betas)\r\n",
        "    \r\n",
        "    # scheduler\r\n",
        "    num_warmup_steps = 0\r\n",
        "    num_training_steps = int(epochs * len(train_dataloader))    \r\n",
        "    scheduler = get_linear_schedule_with_warmup(\r\n",
        "        optimizer, num_warmup_steps, num_training_steps\r\n",
        "    )\r\n",
        "    for epoch_i in range(epochs):\r\n",
        "        print(\"\")\r\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "        logging.info('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "        print('Training...')\r\n",
        "        logging.info('Training...')\r\n",
        "\r\n",
        "        # Measure how long the training epoch takes.\r\n",
        "        t0 = time.time()\r\n",
        "        avg_train_loss = fit(\r\n",
        "            model, optimizer, scheduler, criterion, train_dataloader, t0\r\n",
        "        )                    \r\n",
        "        # Measure how long this epoch took.\r\n",
        "        training_time = format_time(time.time() - t0)\r\n",
        "\r\n",
        "        print(\"\")\r\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "        logging.info(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "        print(\"  Training epoch took: {:}\".format(training_time))\r\n",
        "        logging.info(\"  Training epoch took: {:}\".format(training_time))\r\n",
        "            \r\n",
        "        # ========================================\r\n",
        "        #               Validation\r\n",
        "        # ========================================\r\n",
        "        # After the completion of each training epoch, measure our performance on\r\n",
        "        # our validation set.\r\n",
        "        print(\"\")\r\n",
        "        print(\"Running Validation...\")\r\n",
        "        logging.info(\"Running Validation...\")\r\n",
        "        t0 = time.time()\r\n",
        "        avg_val_loss = validate(model, criterion, validation_dataloader)\r\n",
        "        validation_time = format_time(time.time() - t0)\r\n",
        "        \r\n",
        "        print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\r\n",
        "        print(\"  Validation took: {:}\".format(validation_time))\r\n",
        "        logging.info(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\r\n",
        "        logging.info(\"  Validation took: {:}\".format(validation_time))\r\n",
        "\r\n",
        "        # # Record all statistics from this epoch.\r\n",
        "        # training_stats.append(\r\n",
        "        #     {\r\n",
        "        #         'epoch': epoch_i + 1,\r\n",
        "        #         'Training Loss': avg_train_loss,\r\n",
        "        #         'Valid. Loss': avg_val_loss,\r\n",
        "        #         'Training Time': training_time,\r\n",
        "        #         'Validation Time': validation_time\r\n",
        "        #     }\r\n",
        "        # )\r\n",
        "    # cleaning garbage\r\n",
        "    torch.cuda.empty_cache()\r\n",
        "    gc.collect()\r\n",
        "    print(\"\")\r\n",
        "    print(\"Training complete!\")\r\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\r\n",
        "    logging.info(\"Training complete!\")\r\n",
        "    logging.info(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\r\n",
        "    # save checkpoints\r\n",
        "    torch.save({\r\n",
        "        'iter': int(HEAD_PARAMS[\"epochs\"]) + int(BODY_PARAMS[\"epochs\"]),\r\n",
        "        'model_state_dict': model.state_dict(),\r\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\r\n",
        "    }, \"model.ckpt\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-XJV5_1Jm28"
      },
      "source": [
        "def training_eval_loop(\r\n",
        "    model,\r\n",
        "    train_dataset,\r\n",
        "    val_dataset,\r\n",
        "    head_params=HEAD_PARAMS,\r\n",
        "    body_params=BODY_PARAMS,\r\n",
        "    use_dual_training=USE_DUAL_TRAINING,\r\n",
        "):\r\n",
        "    if use_dual_training:\r\n",
        "        print(\"Training the head pooler layer\")\r\n",
        "        freeze(model)\r\n",
        "        for layer in ['h_index_top_layer', 'h_index_pooler']:\r\n",
        "            unfreeze_layer(model, layer)\r\n",
        "        num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "        print(f'-> {num_parameters} trainable parameters\\n')\r\n",
        "        fit_and_eval(model, train_dataset, val_dataset, **HEAD_PARAMS)\r\n",
        "    print('\\n- Training all layers: ')\r\n",
        "    unfreeze(model)\r\n",
        "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "    print(f'-> {n_parameters} trainable parameters\\n')\r\n",
        "    fit_and_eval(model, train_dataset, val_dataset, **BODY_PARAMS)\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE8rWzWnMNWw"
      },
      "source": [
        "# trying the concat strategy (last 4 hidden layers)\r\n",
        "pooler_in_features = base_model.pooler.dense.out_features*2\r\n",
        "model = TransformerModel(\r\n",
        "    base_model, pooler_in_features=pooler_in_features\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZktLAjnS7cG",
        "outputId": "11df7619-1224-44e1-d745-354247866dae"
      },
      "source": [
        "# Bring to cuda and visualize model\r\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (base_model): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (h_index_pooler): Sequential(\n",
              "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (4): Tanh()\n",
              "    (5): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (h_index_top_layer): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4RLwFfqOPDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0f8c90-5b6d-4666-bc08-03a908c5f413"
      },
      "source": [
        "trained_model = training_eval_loop(\r\n",
        "    model,\r\n",
        "    train_dataset, \r\n",
        "    val_dataset\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the head pooler layer\n",
            "-> 918529 trainable parameters\n",
            "\n",
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 15.51\n",
            "  Training epoch took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 10.83\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 12.30\n",
            "  Training epoch took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 10.46\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 13.69\n",
            "  Training epoch took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 10.28\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:05 (h:mm:ss)\n",
            "\n",
            "- Training all layers: \n",
            "-> 110836993 trainable parameters\n",
            "\n",
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 11.76\n",
            "  Training epoch took: 0:00:02\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 8.43\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 11.97\n",
            "  Training epoch took: 0:00:01\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 8.05\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:00:04 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTMFFnrc-m19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b91f16-2a16-4c8d-89d5-23aa434a525c"
      },
      "source": [
        "!cat log_bert.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14:08:36 INFO Parameters for the current run: {'N': 50, 'NUM_WORKERS': 4, 'MAX_TOKEN_LENGTH': 512, 'MODEL_NAME': 'scibert_uncased', 'USE_DUAL_TRAINING': True, 'USE_LR_SCHEME': False, 'HEAD_PARAMS': {'epochs': 3, 'batch_size': 32, 'lr': 0.0001}, 'BODY_PARAMS': {'epochs': 2, 'batch_size': 6, 'lr': 5e-05, 'lr_transfo': 3e-05, 'lr_decay': 0.95}, 'ADAMW_BETAS': (0.9, 0.999), 'BATCH_SIZE_DF': 2081, 'BATCH_SIZE_TEST': 128}\n",
            "14:08:36 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:36 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "14:08:36 DEBUG Attempting to acquire lock 139986204815144 on /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd.lock\n",
            "14:08:36 INFO Lock 139986204815144 acquired on /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd.lock\n",
            "14:08:36 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:36 DEBUG https://huggingface.co:443 \"GET /allenai/scibert_scivocab_uncased/resolve/main/config.json HTTP/1.1\" 200 385\n",
            "14:08:37 DEBUG Attempting to release lock 139986204815144 on /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd.lock\n",
            "14:08:37 INFO Lock 139986204815144 released on /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd.lock\n",
            "14:08:37 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:37 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "14:08:37 DEBUG Attempting to acquire lock 139986204815144 on /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38.lock\n",
            "14:08:37 INFO Lock 139986204815144 acquired on /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38.lock\n",
            "14:08:37 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:37 DEBUG https://huggingface.co:443 \"GET /allenai/scibert_scivocab_uncased/resolve/main/vocab.txt HTTP/1.1\" 200 227845\n",
            "14:08:37 DEBUG Attempting to release lock 139986204815144 on /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38.lock\n",
            "14:08:37 INFO Lock 139986204815144 released on /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38.lock\n",
            "14:08:37 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:37 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
            "14:08:37 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:38 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "14:08:38 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:38 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
            "14:08:38 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:38 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 404 0\n",
            "14:08:38 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:38 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "14:08:38 DEBUG Starting new HTTPS connection (1): huggingface.co:443\n",
            "14:08:39 DEBUG https://huggingface.co:443 \"HEAD /allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "14:08:39 DEBUG Attempting to acquire lock 139986177598352 on /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb.lock\n",
            "14:08:39 INFO Lock 139986177598352 acquired on /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb.lock\n",
            "14:08:39 DEBUG Starting new HTTPS connection (1): cdn-lfs.huggingface.co:443\n",
            "14:08:39 DEBUG https://cdn-lfs.huggingface.co:443 \"GET /allenai/scibert_scivocab_uncased/e492944d88ac97dee6baa547671d3c526a3d067676883efb058311f4e5882e1a HTTP/1.1\" 200 442221694\n",
            "14:08:45 DEBUG Attempting to release lock 139986177598352 on /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb.lock\n",
            "14:08:45 INFO Lock 139986177598352 released on /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb.lock\n",
            "14:08:48 INFO Tokenizer arguments: {'add_special_tokens': True, 'max_length': 512, 'padding': 'max_length', 'return_attention_mask': True, 'return_tensors': 'pt', 'truncation': True}\n",
            "14:08:48 INFO    45 training samples\n",
            "14:08:48 INFO     5 validation samples\n",
            "14:08:59 INFO ======== Epoch 1 / 3 ========\n",
            "14:08:59 INFO Training...\n",
            "14:09:00 INFO   Average training loss: 14.33\n",
            "14:09:00 INFO   Training epoch took: 0:00:01\n",
            "14:09:00 INFO Running Validation...\n",
            "14:09:01 INFO   Validation Loss: 10.90\n",
            "14:09:01 INFO   Validation took: 0:00:00\n",
            "14:09:01 INFO ======== Epoch 2 / 3 ========\n",
            "14:09:01 INFO Training...\n",
            "14:09:02 INFO   Average training loss: 14.05\n",
            "14:09:02 INFO   Training epoch took: 0:00:01\n",
            "14:09:02 INFO Running Validation...\n",
            "14:09:02 INFO   Validation Loss: 10.62\n",
            "14:09:02 INFO   Validation took: 0:00:00\n",
            "14:09:02 INFO ======== Epoch 3 / 3 ========\n",
            "14:09:02 INFO Training...\n",
            "14:09:03 INFO   Average training loss: 13.65\n",
            "14:09:03 INFO   Training epoch took: 0:00:01\n",
            "14:09:03 INFO Running Validation...\n",
            "14:09:04 INFO   Validation Loss: 10.49\n",
            "14:09:04 INFO   Validation took: 0:00:00\n",
            "14:09:04 INFO Training complete!\n",
            "14:09:04 INFO Total training took 0:00:05 (h:mm:ss)\n",
            "14:09:04 INFO ======== Epoch 1 / 2 ========\n",
            "14:09:04 INFO Training...\n",
            "14:09:05 INFO   Average training loss: 12.61\n",
            "14:09:05 INFO   Training epoch took: 0:00:01\n",
            "14:09:05 INFO Running Validation...\n",
            "14:09:06 INFO   Validation Loss: 8.79\n",
            "14:09:06 INFO   Validation took: 0:00:00\n",
            "14:09:06 INFO ======== Epoch 2 / 2 ========\n",
            "14:09:06 INFO Training...\n",
            "14:09:07 INFO   Average training loss: 11.42\n",
            "14:09:07 INFO   Training epoch took: 0:00:01\n",
            "14:09:07 INFO Running Validation...\n",
            "14:09:08 INFO   Validation Loss: 8.34\n",
            "14:09:08 INFO   Validation took: 0:00:00\n",
            "14:09:08 INFO Training complete!\n",
            "14:09:08 INFO Total training took 0:00:04 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HgO9Z-Bs5Up"
      },
      "source": [
        "# Save torch model to disk and convert it to tensorflow for embedding extraction\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuN79viss0hi",
        "outputId": "379fa454-25e4-4679-afa3-6c1aef5c9f7b"
      },
      "source": [
        "!pip install onnx\r\n",
        "# For onnx-tensorflow, you may want to refer to the installation guide here: https://github.com/onnx/onnx-tensorflow\r\n",
        "!git clone https://github.com/onnx/onnx-tensorflow.git\r\n",
        "%cd onnx-tensorflow\r\n",
        "!pip install -e .\r\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx) (53.0.0)\n",
            "fatal: destination path 'onnx-tensorflow' already exists and is not an empty directory.\n",
            "/content/onnx-tensorflow/onnx-tensorflow\n",
            "Obtaining file:///content/onnx-tensorflow/onnx-tensorflow\n",
            "Requirement already satisfied: onnx>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from onnx-tf==1.7.0) (1.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from onnx-tf==1.7.0) (3.13)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.6/dist-packages (from onnx-tf==1.7.0) (0.8.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->onnx-tf==1.7.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->onnx-tf==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->onnx-tf==1.7.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from onnx>=1.7.0->onnx-tf==1.7.0) (1.19.5)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons->onnx-tf==1.7.0) (2.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx>=1.7.0->onnx-tf==1.7.0) (53.0.0)\n",
            "Installing collected packages: onnx-tf\n",
            "  Found existing installation: onnx-tf 1.7.0\n",
            "    Can't uninstall 'onnx-tf'. No files were found to uninstall.\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGaOAED3youT",
        "outputId": "df3bea2d-eeb3-4f08-873d-7d78f3aa7041"
      },
      "source": [
        "!pip install tensorflow==2.4.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.4.0 in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (3.12.4)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (0.36.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.4.0) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow==2.4.0) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.24.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZP1x0yps9nj",
        "outputId": "446a2fff-3c61-44c5-9bc3-0d91359fde7c"
      },
      "source": [
        "from torch.onnx import export\r\n",
        "\r\n",
        "model_onnx_path = \"./models/model.onnx\"\r\n",
        "dummy_input = (\r\n",
        "    train_dataset[0][0].unsqueeze(0).to(device), \r\n",
        "    train_dataset[0][0].unsqueeze(0).to(device),\r\n",
        ")\r\n",
        "input_names = [\"input_ids\", \"attention_mask\"]\r\n",
        "output_names = [\"logit\"]\r\n",
        "export(\r\n",
        "    trained_model.base_model, \r\n",
        "    dummy_input, \r\n",
        "    model_onnx_path, \r\n",
        "    input_names=input_names, \r\n",
        "    output_names=output_names,\r\n",
        "    opset_version=11\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py:194: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py:1760: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  input_tensor.shape[chunk_dim] == tensor_shape for input_tensor in input_tensors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up1YFofu9yjF"
      },
      "source": [
        "# Load ONNX model and convert to TensorFlow format\r\n",
        "model_onnx = onnx.load('./models/model.onnx')\r\n",
        "\r\n",
        "tf_rep = prepare(model_onnx)\r\n",
        "\r\n",
        "# Export model as .pb file\r\n",
        "tf_rep.export_graph('./models/model_simple.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9TtaBF2rPK6"
      },
      "source": [
        "def batch_predict(\r\n",
        "    model, \r\n",
        "    df_test, \r\n",
        "    batch_size_df=BATCH_SIZE_DF, \r\n",
        "    batch_size_test=BATCH_SIZE_TEST, \r\n",
        "    tokenizer=tokenizer, \r\n",
        "    tokenizer_kwargs=tokenizer_kwargs\r\n",
        "):\r\n",
        "    n = len(df_test)\r\n",
        "    size_groups = np.arange(n) // batch_size_df\r\n",
        "    # (batch_size, pred_dim) regression\r\n",
        "    predictions = torch.empty((0, 1)).to(device)\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    for i, batch_df in tqdm(df_test.groupby(size_groups)):\r\n",
        "        batch_len = len(batch_df)\r\n",
        "        test_dataset = get_tokens_labels(\r\n",
        "            batch_df, tokenizer, progress=False, **tokenizer_kwargs\r\n",
        "        )\r\n",
        "        print(f\"Token encoded for batch {i}\")\r\n",
        "        test_dataloader = DataLoader(\r\n",
        "            test_dataset,  # The test samples.\r\n",
        "            batch_size=batch_size_test,\r\n",
        "            shuffle=False, # Select batches not randomly (by size)\r\n",
        "            num_workers=NUM_WORKERS, # Train with this batch size.\r\n",
        "            pin_memory=True\r\n",
        "        )\r\n",
        "        with torch.no_grad():\r\n",
        "            for ids in test_dataloader:\r\n",
        "                pred = model(ids[0].cuda())\r\n",
        "                predictions = torch.cat((predictions, pred.view(-1, 1)))\r\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUE-zu8wpXq"
      },
      "source": [
        "predictions = batch_predict(\r\n",
        "    model, df_test\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8etVlrWBydlj"
      },
      "source": [
        "df_test[\"h_index\"] = predictions.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLHUEc6UyieU"
      },
      "source": [
        "df_test.csv(f\"predictions.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}